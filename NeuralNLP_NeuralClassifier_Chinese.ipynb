{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "NeuralNLP-NeuralClassifier-Chinese.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbJiCHZHBJ-x"
      },
      "source": [
        "## 1. Set up the GPU\n",
        "\n",
        "First, make sure your colab has access to a GPU.  \n",
        "Select Runtime -> Change runtime type > GPU.\n",
        "\n",
        "Check to see if this works by running the following cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wazOTw_BxBhl",
        "outputId": "cfe6293f-43ea-40eb-f7bf-859807f98940",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOfaBRyuypz3",
        "outputId": "d6b65685-bd94-441f-ee93-7ecf66a9e6a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "import os\n",
        "\n",
        "os.environ['USER'] = 'username'\n",
        "os.environ['PASS'] = 'password'\n",
        "os.environ['REPO'] = 'NeuralNLP-NeuralClassifier-Chinese'\n",
        "\n",
        "!git clone https://$USER:$PASS@github.com/$USER/$REPO.git\n",
        "\n",
        "%cd NeuralNLP-NeuralClassifier-Chinese"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'NeuralNLP-NeuralClassifier-Chinese'...\n",
            "remote: Enumerating objects: 59, done.\u001b[K\n",
            "remote: Counting objects: 100% (59/59), done.\u001b[K\n",
            "remote: Compressing objects: 100% (50/50), done.\u001b[K\n",
            "remote: Total 59 (delta 6), reused 59 (delta 6), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (59/59), done.\n",
            "/content/NeuralNLP-NeuralClassifier-Chinese\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4l5edkl2ZT17",
        "outputId": "1ff378f4-d3f4-410d-b6bf-a3ff4f56c4f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/NeuralNLP-NeuralClassifier-Chinese\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZt8T_wiLSK8",
        "outputId": "f059ff9a-2fe8-4b0b-dc96-30076dc6491a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 904
        }
      },
      "source": [
        "!python train.py conf/train.json"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Use dataset to generate dict.\n",
            "Size of doc_label dict is 102\n",
            "Size of doc_token dict is 114596\n",
            "Size of doc_char dict is 59\n",
            "Size of doc_token_ngram dict is 0\n",
            "Size of doc_keyword dict is 0\n",
            "Size of doc_topic dict is 0\n",
            "Shrink dict over.\n",
            "Size of doc_label dict is 102\n",
            "Size of doc_token dict is 95439\n",
            "Size of doc_char dict is 59\n",
            "Size of doc_token_ngram dict is 0\n",
            "Size of doc_keyword dict is 0\n",
            "Size of doc_topic dict is 0\n",
            "Train performance at epoch 1 is precision: 0.941382, recall: 0.334103, fscore: 0.493174, macro-fscore: 0.059434, right: 22146, predict: 23525, standard: 66285.\n",
            "Loss is: 0.074346.\n",
            "Validate performance at epoch 1 is precision: 0.940883, recall: 0.330680, fscore: 0.489368, macro-fscore: 0.058863, right: 2451, predict: 2605, standard: 7412.\n",
            "Loss is: 0.076232.\n",
            "test performance at epoch 1 is precision: 0.936856, recall: 0.312141, fscore: 0.468265, macro-fscore: 0.056248, right: 8086, predict: 8631, standard: 25905.\n",
            "Loss is: 0.079445.\n",
            "Epoch 1 cost time: 40 second\n",
            "Train performance at epoch 2 is precision: 0.947352, recall: 0.508184, fscore: 0.661515, macro-fscore: 0.164083, right: 33685, predict: 35557, standard: 66285.\n",
            "Loss is: 0.049080.\n",
            "Validate performance at epoch 2 is precision: 0.929679, recall: 0.485159, fscore: 0.637589, macro-fscore: 0.138583, right: 3596, predict: 3868, standard: 7412.\n",
            "Loss is: 0.053747.\n",
            "test performance at epoch 2 is precision: 0.935510, recall: 0.444625, fscore: 0.602768, macro-fscore: 0.133057, right: 11518, predict: 12312, standard: 25905.\n",
            "Loss is: 0.058149.\n",
            "Epoch 2 cost time: 40 second\n",
            "Train performance at epoch 3 is precision: 0.961415, recall: 0.630761, fscore: 0.761754, macro-fscore: 0.271393, right: 41810, predict: 43488, standard: 66285.\n",
            "Loss is: 0.035929.\n",
            "Validate performance at epoch 3 is precision: 0.936698, recall: 0.580950, fscore: 0.717129, macro-fscore: 0.233591, right: 4306, predict: 4597, standard: 7412.\n",
            "Loss is: 0.043254.\n",
            "test performance at epoch 3 is precision: 0.937688, recall: 0.517583, fscore: 0.666998, macro-fscore: 0.202170, right: 13408, predict: 14299, standard: 25905.\n",
            "Loss is: 0.049035.\n",
            "Epoch 3 cost time: 41 second\n",
            "Train performance at epoch 4 is precision: 0.967713, recall: 0.711715, fscore: 0.820203, macro-fscore: 0.363615, right: 47176, predict: 48750, standard: 66285.\n",
            "Loss is: 0.027964.\n",
            "Validate performance at epoch 4 is precision: 0.935632, recall: 0.633432, fscore: 0.755430, macro-fscore: 0.296076, right: 4695, predict: 5018, standard: 7412.\n",
            "Loss is: 0.038453.\n",
            "test performance at epoch 4 is precision: 0.934983, recall: 0.560124, fscore: 0.700560, macro-fscore: 0.255651, right: 14510, predict: 15519, standard: 25905.\n",
            "Loss is: 0.045217.\n",
            "Epoch 4 cost time: 40 second\n",
            "Train performance at epoch 5 is precision: 0.968921, recall: 0.776043, fscore: 0.861822, macro-fscore: 0.433146, right: 51440, predict: 53090, standard: 66285.\n",
            "Loss is: 0.022581.\n",
            "Validate performance at epoch 5 is precision: 0.925152, recall: 0.675391, fscore: 0.780785, macro-fscore: 0.343083, right: 5006, predict: 5411, standard: 7412.\n",
            "Loss is: 0.035783.\n",
            "test performance at epoch 5 is precision: 0.927437, recall: 0.590581, fscore: 0.721634, macro-fscore: 0.285021, right: 15299, predict: 16496, standard: 25905.\n",
            "Loss is: 0.043129.\n",
            "Epoch 5 cost time: 40 second\n",
            "Best test performance at epoch 5 is precision: 0.927437, recall: 0.590581, fscore: 0.721634, macro-fscore: 0.285021, right: 15299, predict: 16496, standard: 25905.\n",
            "Loss is: 0.043129.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaFvEpEvLJD0",
        "outputId": "476924cf-aab8-4646-c4d1-213bf73cb9a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "!python eval.py conf/train.json"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Performance is precision: 0.927437, recall: 0.590581, fscore: 0.721634, right: 15299, predict: 16496, standard: 25905.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHYOK-OCLOrO",
        "outputId": "5d3346a8-861c-4d7a-d4ce-071df70dcf1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "!python predict.py conf/train.json data/predict.json"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"predict.py\", line 94, in <module>\n",
            "    for line in codecs.open(sys.argv[2], \"r\", predictor.dataset.CHARSET):\n",
            "  File \"/usr/lib/python3.6/codecs.py\", line 897, in open\n",
            "    file = builtins.open(filename, mode, buffering)\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'data/predict.json'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrcQpITQAGvA"
      },
      "source": [
        "### Code directly on Colab\n",
        "\n",
        "* Modify your code on Colab through the left panel and double-clicking the file\n",
        "* Push to Github from Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deIpj_TTANnW",
        "outputId": "23218898-dd3d-4de8-d5e8-53cff819a9be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "!git add .\n",
        "!git config --global user.email \"xxxxxxx@utexas.edu\"\n",
        "!git config --global user.name \"username\"\n",
        "!git commit -m \"Message\"\n",
        "!git push origin master"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "On branch main\n",
            "Your branch is ahead of 'origin/main' by 1 commit.\n",
            "  (use \"git push\" to publish your local commits)\n",
            "\n",
            "nothing to commit, working tree clean\n",
            "error: src refspec master does not match any.\n",
            "error: failed to push some refs to 'https://jiayi98:JUDYzhou959!@github.com/jiayi98/NeuralNLP-NeuralClassifier-Chinese.git'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "973WwC5u0ulC"
      },
      "source": [
        "Using your updated code, loop back to step 5 and retrain until you're satisfied."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNlhPhWuSO34",
        "outputId": "720be958-3373-432c-d2d8-2ebd0dc4b42c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "!git push"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counting objects: 59, done.\n",
            "Delta compression using up to 2 threads.\n",
            "Compressing objects: 100% (58/58), done.\n",
            "Writing objects: 100% (59/59), 612.16 MiB | 9.49 MiB/s, done.\n",
            "Total 59 (delta 6), reused 0 (delta 0)\n",
            "remote: Resolving deltas: 100% (6/6), completed with 5 local objects.\u001b[K\n",
            "remote: warning: GH001: Large files detected. You may want to try Git Large File Storage - https://git-lfs.github.com.\u001b[K\n",
            "remote: warning: See http://git.io/iEPt8g for more information.\u001b[K\n",
            "remote: warning: File checkpoint_dir_rcv1/FastText_1 is 69.98 MB; this is larger than GitHub's recommended maximum file size of 50.00 MB\u001b[K\n",
            "remote: warning: File checkpoint_dir_rcv1/FastText_2 is 69.98 MB; this is larger than GitHub's recommended maximum file size of 50.00 MB\u001b[K\n",
            "remote: warning: File checkpoint_dir_rcv1/FastText_3 is 69.98 MB; this is larger than GitHub's recommended maximum file size of 50.00 MB\u001b[K\n",
            "remote: warning: File checkpoint_dir_rcv1/FastText_4 is 69.98 MB; this is larger than GitHub's recommended maximum file size of 50.00 MB\u001b[K\n",
            "remote: warning: File checkpoint_dir_rcv1/FastText_5 is 69.98 MB; this is larger than GitHub's recommended maximum file size of 50.00 MB\u001b[K\n",
            "remote: warning: File checkpoint_dir_rcv1/TextCNN_1 is 70.94 MB; this is larger than GitHub's recommended maximum file size of 50.00 MB\u001b[K\n",
            "remote: warning: File checkpoint_dir_rcv1/TextCNN_2 is 70.94 MB; this is larger than GitHub's recommended maximum file size of 50.00 MB\u001b[K\n",
            "remote: warning: File checkpoint_dir_rcv1/TextCNN_3 is 70.94 MB; this is larger than GitHub's recommended maximum file size of 50.00 MB\u001b[K\n",
            "remote: warning: File checkpoint_dir_rcv1/TextCNN_4 is 70.94 MB; this is larger than GitHub's recommended maximum file size of 50.00 MB\u001b[K\n",
            "remote: warning: File checkpoint_dir_rcv1/TextCNN_5 is 70.94 MB; this is larger than GitHub's recommended maximum file size of 50.00 MB\u001b[K\n",
            "remote: This repository moved. Please use the new location:\u001b[K\n",
            "remote:   https://github.com/Jiayi98/NeuralNLP-NeuralClassifier-Chinese.git\u001b[K\n",
            "To https://github.com/jiayi98/NeuralNLP-NeuralClassifier-Chinese.git\n",
            "   0be2f76..0263a17  main -> main\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mM_7vOlXTMHM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}